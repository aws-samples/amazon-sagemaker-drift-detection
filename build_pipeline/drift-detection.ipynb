{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Detection  Notebook\n",
    "\n",
    "This notebook will exercise the drift detection MLOps pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "ðŸ‘‡ Set the project name for your drift pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"<<project_name>>\"  # << Update this drift detection project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get back the project id and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "sess = sagemaker.session.Session()\n",
    "region_name = sess._region_name\n",
    "sm_client = sess.sagemaker_client\n",
    "project_id = sm_client.describe_project(ProjectName=project_name)[\"ProjectId\"]\n",
    "\n",
    "print(f\"Project: {project_name} ({project_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "\n",
    "Let's copy some trip data and taxi zone files to the input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "# Download trip data and taxi zones to input folder\n",
    "download_uri = \"s3://nyc-tlc/trip data/green_tripdata_2018-02.csv\"\n",
    "S3Downloader().download(download_uri, \"input/data\")\n",
    "download_uri = \"s3://nyc-tlc/misc/taxi_zones.zip\"\n",
    "S3Downloader().download(download_uri, \"input/zones\")\n",
    "\n",
    "# Upload input to the target location\n",
    "artifact_bucket = f\"sagemaker-project-{project_id}-{region_name}\"\n",
    "input_data_uri = f\"s3://{artifact_bucket}/{project_id}/input\"\n",
    "S3Uploader().upload(\"input\", input_data_uri)\n",
    "\n",
    "print(\"Listing input files:\")\n",
    "for s3_uri in S3Downloader.list(input_data_uri):\n",
    "    print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Start the pipeline now that we have uploaded some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = f\"{project_name}-pipeline\"\n",
    "pipeline = Pipeline(pipeline_name)\n",
    "\n",
    "# Start pipeline\n",
    "execution = pipeline.start()\n",
    "execution_name = execution.arn.split(\"/\")[-1]\n",
    "\n",
    "print(f\"Waiting for execution: {execution_name} for pipeline {pipeline_name}...\")\n",
    "execution.wait()\n",
    "execution_status = execution.describe()[\"PipelineExecutionStatus\"]\n",
    "print(f\"Status: {execution_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the execution steps.  Note that we have baseline and training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in execution.list_steps():\n",
    "    print(\"Step: {}, Status: {}\".format(step[\"StepName\"], step[\"StepStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Get the estimator for the training job in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "\n",
    "def get_execution_step(step_name):\n",
    "    return [\n",
    "        step[\"Metadata\"]\n",
    "        for step in execution.list_steps()\n",
    "        if step[\"StepName\"] == step_name\n",
    "    ]\n",
    "\n",
    "\n",
    "training_job_arn = get_execution_step(\"TrainModel\")[0][\"TrainingJob\"][\"Arn\"]\n",
    "training_job_name = training_job_arn.split(\"/\")[-1]\n",
    "estimator = Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Debugger XGBoost training report\n",
    "\n",
    "SageMaker Debugger generates a [XGBoost Training Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-training-xgboost-report.html) by a processing jobs that run concurrent to the training job. Let's wait for it to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get name of the xgboost training report\n",
    "xgb_report_job_name = [\n",
    "    rule[\"RuleEvaluationJobArn\"].split(\"/\")[-1]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"CreateXgboostReport\" in rule[\"RuleConfigurationName\"]\n",
    "][0]\n",
    "\n",
    "print(\"Waiting for XGBoost training report to complete...\")\n",
    "sm_client.get_waiter(\"processing_job_completed_or_stopped\").wait(\n",
    "    ProcessingJobName=xgb_report_job_name\n",
    ")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â„¹ï¸ The code below will download the output from the Debugger report in the `report` folder.  Click the link to open the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "# Get the s3 output\n",
    "report_uri = sm_client.describe_processing_job(ProcessingJobName=xgb_report_job_name)[\n",
    "    \"ProcessingOutputConfig\"\n",
    "][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "# Download the notebook from the report\n",
    "S3Downloader().download(f\"{report_uri}/xgboost_report.html\", \"report\")\n",
    "FileLink(\"report/xgboost_report.html\", result_html_prefix=\"Open Report: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approve Model\n",
    "\n",
    "ðŸ›‘ Once we are happy with this training job, we can [Update the Approval Status](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry-approve.html) of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = get_execution_step(\"RegisterModel\")[0][\"RegisterModel\"][\"Arn\"]\n",
    "model_package_version = model_package_arn.split(\"/\")[-1]\n",
    "print(f\"Model version: {model_package_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the status to approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\": model_package_arn,\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "model_package_update_response = sm_client.update_model_package(\n",
    "    **model_package_update_input_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "\n",
    "Now that our model is approve, the deployment pipeline will kick off shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import WaiterError\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Define the predictor for staging\n",
    "def wait_for_predictor(stage_name):\n",
    "    try:\n",
    "        endpoint_name = f\"sagemaker-{project_name}-{stage_name}\"\n",
    "        predictor = Predictor(\n",
    "            endpoint_name, serializer=CSVSerializer(), deserializer=JSONDeserializer()\n",
    "        )\n",
    "        print(\n",
    "            f\"Waiting for {stage_name} endpoint: {predictor.endpoint_name} to be deployed...\"\n",
    "        )\n",
    "        sm_client.get_waiter(\"endpoint_in_service\").wait(\n",
    "            EndpointName=predictor.endpoint_name\n",
    "        )\n",
    "        print(\"Ready\")\n",
    "        return predictor\n",
    "    except WaiterError as err:\n",
    "        error_message = err.last_response[\"Error\"][\"Message\"]\n",
    "        if error_message.startswith(\"Could not find endpoint\"):\n",
    "            err = Exception(f\"Endpoint {endpoint_name} not found.\")\n",
    "        raise err\n",
    "\n",
    "\n",
    "predictor = wait_for_predictor(\"staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Staging\n",
    "\n",
    "Let's send some traffic to the staging endpoint with the following payload:\n",
    "\n",
    "| passenger_count\t| pickup_latitude\t| pickup_longitude\t| dropoff_latitude\t| dropoff_longitude\t| geo_distance\t| hour\t| weekday\t| month |\n",
    "| -| - | - | - | - | - | - | - | - |\n",
    "| 1\t| -73.986114\t| 40.685634\t| -73.936794\t| 40.715370\t| 5.318025\t| 7\t| 0\t| 2 |\n",
    "\n",
    "We expect approximately a $20 fare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = \"1,-73.986114,40.685634,-73.936794,40.715370,5.318025,7,0,2\"\n",
    "predictor.predict(data=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approve Staging\n",
    "\n",
    "ðŸ›‘ Click the link below to head over to the AWS Code Pipeline and approve the staging deployment to kick off the production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\n",
    "    f'Open <a target=\"_blank\" href=\"https://{region_name}.console.aws.amazon.com/codesuite/codepipeline/pipelines/sagemaker-{project_name}-deploy/view?region={region_name}\">Code Pipeline</a> in a new window'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Production\n",
    "\n",
    "After a few minutes our production endpoint will start to be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = wait_for_predictor(\"prod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And confirm that data capture is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture = sm_client.describe_endpoint(EndpointName=predictor.endpoint_name)[\n",
    "    \"DataCaptureConfig\"\n",
    "]\n",
    "print(f\"Data capture is: {data_capture['CaptureStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data Capture\n",
    "\n",
    "Let's send some traffic to the producition endpoint, which our [Data Quality Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-data-quality.html) should detect as drifting from the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for n in range(100):\n",
    "    predictor.predict(data=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we have received some outputs to our data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture_uri = data_capture[\"DestinationS3Uri\"]\n",
    "data_capture_files = S3Downloader.list(data_capture_uri)\n",
    "\n",
    "print(\"Found {} files\".format(len(data_capture_files)))\n",
    "\n",
    "if data_capture[\"EnableCapture\"] and len(data_capture_files) > 0:\n",
    "    # Get the first line of the most recent file\n",
    "    event = json.loads(S3Downloader.read_file(data_capture_files[-1]).split(\"\\n\")[0])\n",
    "    print(\"\\nLast file:\\n{}\".format(json.dumps(event, indent=2)))\n",
    "elif len(data_capture_files) == 0:\n",
    "    print(\"No files yet, please rerun this cell in a few seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download the validation dataset from the latest processing job, and tweak some of the columns to change the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import random\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "\n",
    "def get_latest_processed_data():\n",
    "    execution_arn = sm_client.list_pipeline_executions(\n",
    "        PipelineName=pipeline_name, SortBy=\"CreationTime\"\n",
    "    )[\"PipelineExecutionSummaries\"][0][\"PipelineExecutionArn\"]\n",
    "    steps = sm_client.list_pipeline_execution_steps(\n",
    "        PipelineExecutionArn=execution_arn, SortOrder=\"Ascending\"\n",
    "    )[\"PipelineExecutionSteps\"]\n",
    "    preprocess_arn = next(\n",
    "        item[\"Metadata\"][\"ProcessingJob\"][\"Arn\"]\n",
    "        for item in steps\n",
    "        if item[\"StepName\"] == \"PreprocessData\"\n",
    "    )\n",
    "    job_outputs = sm_client.describe_processing_job(\n",
    "        ProcessingJobName=preprocess_arn.split(\"/\")[1]\n",
    "    )[\"ProcessingOutputConfig\"][\"Outputs\"]\n",
    "    validation_uri = next(\n",
    "        item[\"S3Output\"][\"S3Uri\"]\n",
    "        for item in job_outputs\n",
    "        if item[\"OutputName\"] == \"validation\"\n",
    "    )\n",
    "    return validation_uri\n",
    "\n",
    "\n",
    "dataset_location = get_latest_processed_data()\n",
    "S3Downloader().download(dataset_location, \"preprocessed\")\n",
    "df = pd.read_csv(\"preprocessed/validation.csv\", header=None)\n",
    "\n",
    "# Changing the distribution of data to artificially cause an alarm\n",
    "df[1] = random.choices([1, 2, 3, 4, 5, 6], weights=[2, 1, 2, 5, 2, 1], k=df.shape[0])\n",
    "df[6] = df[1].apply(lambda x: 70 * random.betavariate(2.5, 2))\n",
    "tweaked_rows = df.drop(0, axis=1).to_csv(header=False, index=False).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a series of prediction requests in the background every 10 minutes with this  data to cause an artificial model monitoring alarm to be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "\n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        for i in range(10000):\n",
    "            predictor.predict(data=tweaked_rows[i % len(tweaked_rows)])\n",
    "        time.sleep(10 * 60)\n",
    "\n",
    "\n",
    "Thread(target=invoke_endpoint_forever).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor\n",
    "\n",
    "Let's check that we have a monitor configured and that its schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "model_monitor = predictor.list_monitors()[0]\n",
    "model_monitor_status = model_monitor.describe_schedule()[\"MonitoringScheduleStatus\"]\n",
    "print(f\"Model Monitoring: {model_monitor_status}\")\n",
    "\n",
    "now = datetime.now(tzlocal())\n",
    "next_hour = (now + timedelta(hours=1)).replace(minute=0)\n",
    "scheduled_diff = (next_hour - now).seconds // 60\n",
    "print(\"Next schedule in {} minutes\".format(scheduled_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the latest execution and output the status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_executions = model_monitor.list_executions()\n",
    "if len(monitor_executions) == 0:\n",
    "    raise (Exception(\"Please wait, no monitor executions available yet\"))\n",
    "\n",
    "# Get the latest monitor status\n",
    "monitor_status = monitor_executions[0].describe()[\"ProcessingJobStatus\"]\n",
    "if monitor_status == \"Completed\":\n",
    "    monitor_message = monitor_executions[0].describe()[\"ExitMessage\"]\n",
    "    print(f\"Latest execution: {monitor_message}\")\n",
    "else:\n",
    "    print(f\"Latest execution: {monitor_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Model Monitor report\n",
    "\n",
    "ðŸ›‘ Browse to the model monitoring results in SageMaker Studio to download and run a report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain\n",
    "\n",
    "When the model monitoring schedule runs it will publish Amazon [CloudWatch Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-interpreting-cloudwatch.html).  If drift is detected about a pre-configured threshold then an Amazon CloudWatch metric will Alarm resulting in the SageMaker pipeline to be re-trained.\n",
    "\n",
    "You can simulate drift by putting a metric value above the threshold of `0.5` directly into CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "import random\n",
    "\n",
    "\n",
    "cloudwatch = boto3.client(\"cloudwatch\")\n",
    "\n",
    "# Define the metric name and threshold\n",
    "endpoint_name = predictor.endpoint_name\n",
    "schedule_name = f\"{endpoint_name}-threshold\"\n",
    "metric_name = \"feature_baseline_drift_fare_amount\"\n",
    "metric_threshold = 0.5\n",
    "\n",
    "# Put a new metric to trigger an alaram\n",
    "def put_drift_metric(value):\n",
    "    print(\"Putting metric: {}\".format(value))\n",
    "    response = cloudwatch.put_metric_data(\n",
    "        Namespace=\"aws/sagemaker/Endpoints/data-metrics\",\n",
    "        MetricData=[\n",
    "            {\n",
    "                \"MetricName\": metric_name,\n",
    "                \"Dimensions\": [\n",
    "                    {\"Name\": \"MonitoringSchedule\", \"Value\": schedule_name},\n",
    "                    {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "                ],\n",
    "                \"Timestamp\": datetime.now(),\n",
    "                \"Value\": value,\n",
    "                \"Unit\": \"None\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_drift_stats():\n",
    "    response = cloudwatch.get_metric_statistics(\n",
    "        Namespace=\"aws/sagemaker/Endpoints/data-metrics\",\n",
    "        MetricName=metric_name,\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"MonitoringSchedule\", \"Value\": schedule_name},\n",
    "            {\"Name\": \"Endpoint\", \"Value\": endpoint_name},\n",
    "        ],\n",
    "        StartTime=datetime.now() - timedelta(minutes=2),\n",
    "        EndTime=datetime.now(),\n",
    "        Period=1,\n",
    "        Statistics=[\"Average\"],\n",
    "        Unit=\"None\",\n",
    "    )\n",
    "    if \"Datapoints\" in response and len(response[\"Datapoints\"]) > 0:\n",
    "        return response[\"Datapoints\"][0][\"Average\"]\n",
    "    return 0\n",
    "\n",
    "\n",
    "print(\"Simluate drift on endpoint: {}\".format(endpoint_name))\n",
    "\n",
    "while True:\n",
    "    put_drift_metric(round(random.uniform(metric_threshold, 1.0), 4))\n",
    "    drift_stats = get_drift_stats()\n",
    "    print(\"Average drift amount: {}\".format(get_drift_stats()))\n",
    "    if drift_stats > metric_threshold:\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the CloudWatch metric Alarm click on the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\n",
    "    f'Open <a target=\"_blank\" href=\"https://{region_name}.console.aws.amazon.com/cloudwatch/home?region={region_name}#alarmsV2:alarm/{schedule_name}\">CloudWatch Alarm</a> in new window'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will result in a new SageMaker pipeline execution starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_pipeline_execution = sm_client.list_pipeline_executions(\n",
    "    PipelineName=pipeline_name,\n",
    ")[\"PipelineExecutionSummaries\"][0]\n",
    "latest_execution_status = latest_pipeline_execution[\"PipelineExecutionStatus\"]\n",
    "time_ago = datetime.now(tzlocal()) - latest_pipeline_execution[\"StartTime\"]\n",
    "\n",
    "print(\n",
    "    f\"Latest pipeline: {pipeline_name} execution: {latest_execution_status} started {time_ago.total_seconds()/60:0.2f} mins ago\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that this was triggered by Drift by inspecting the InputSource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sm_client.list_pipeline_parameters_for_execution(\n",
    "    PipelineExecutionArn=latest_pipeline_execution[\"PipelineExecutionArn\"],\n",
    ")\n",
    "input_source = [\n",
    "    p[\"Value\"] for p in params[\"PipelineParameters\"] if p[\"Name\"] == \"InputSource\"\n",
    "][0]\n",
    "print(f\"Pipeline execution started with InputSource: {input_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's list the steps of that execution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_steps = sm_client.list_pipeline_execution_steps(\n",
    "    PipelineExecutionArn=latest_pipeline_execution[\"PipelineExecutionArn\"],\n",
    ")[\"PipelineExecutionSteps\"]\n",
    "for step in execution_steps:\n",
    "    print(\"Step: {}, Status: {}\".format(step[\"StepName\"], step[\"StepStatus\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Great now you have completed all the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Execute the following cell to delete any registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.list_model_packages(ModelPackageGroupName=project_name)\n",
    "for model_package in response[\"ModelPackageSummaryList\"]:\n",
    "    print(\"Deleting Version {}\".format(model_package[\"ModelPackageArn\"].split(\"/\")[-1]))\n",
    "    sm_client.delete_model_package(ModelPackageName=model_package[\"ModelPackageArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to delete cloudformation stacks\n",
    "\n",
    "1. SageMaker prod endpoint\n",
    "2. SageMaker staging endpoint\n",
    "3. SageMaker Pipeline Workflow and Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "cfn = boto3.client(\"cloudformation\")\n",
    "\n",
    "for stack_name in [\n",
    "    f\"sagemaker-{project_name}-deploy-prod\",\n",
    "    f\"sagemaker-{project_name}-deploy-staging\",\n",
    "    f\"sagemaker-{project_name}-pipeline\",\n",
    "]:\n",
    "    print(\"Deleting stack: {}\".format(stack_name))\n",
    "    cfn.delete_stack(StackName=stack_name)\n",
    "    cfn.get_waiter(\"stack_delete_complete\").wait(StackName=stack_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will clean up all objects in the artifact bucket and delete the SageMaker project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource(\"s3\")\n",
    "s3_artifact_bucket = s3_resource.Bucket(artifact_bucket)\n",
    "s3_artifact_bucket.object_versions.delete()\n",
    "print(\"Artifact bucket objects deleted\")\n",
    "\n",
    "sm_client.delete_project(ProjectName=project_name)\n",
    "print(\"SageMaker Project deleted\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "07c1d6c68b7b22b50965762993b154aa5a1dd6aa65a365988d7d4c27c573599b"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
